# -*- coding: utf-8 -*-
"""Paweł_Zych__task1 (3).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16wWeLk_OM6ix5EbwAlBi_XV5MJnaziI6

#Opis zestawu danych
Jest to zbiór danych zawierający znaki amerykańskiego języka migowego:
* zawira 4 klas - "0", "A", "B", "C".
* klasa "A" 300 zdjęć jpg
* klasa "B" 300 zdjęć jpg
* klasa "C" 300 zdjęć jpg
* klasa "0" 300 zdjęć jpg

Opis: Celem zadania jest stworzenie modelu klasyfikującego znaki amerykańskiego języka migowego do jednej z 4 klas - "0", "A", "B", "C".
"""

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
import pathlib
from google.colab import drive
from tensorflow.keras.optimizers import RMSprop
from sklearn.metrics import classification_report

#montowanie dysku
drive.mount('/content/drive', force_remount=True)

#zliczenie liczby zdjęc jpg
data_dir=pathlib.Path('/content/drive/MyDrive/data')
image_count = len(list(data_dir.glob('*/*.jpg')))
print(image_count)

batch_size = 50
img_height = 300
img_width = 300

# podział danych treningowych na zbiór treningowy i walidacyjny, testowy
train_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size,
  )

val_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.1,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size,
  )

test_ds = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    validation_split=0.1,
    subset="validation",
    seed=123,
    image_size=(img_height, img_width),
    batch_size=batch_size
    )

#wypisanie nazw klas 
class_names = train_ds.class_names
print(class_names)

print(len(class_names))
num_classes = len(class_names)

AUTOTUNE = tf.data.AUTOTUNE

train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

#generowaniu dodatkowych danych szkoleniowych z istniejących
data_augmentation = tf.keras.Sequential(
  [
    layers.RandomFlip("horizontal",
                      input_shape=(img_height,
                                  img_width,
                                  3)),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
  ]
)

#generowaniu dodatkowych danych szkoleniowych z istniejących
data_augmentation = keras.Sequential(
  [
    
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
  ]
)

#tworzenie modelu

model = tf.keras.Sequential([
  data_augmentation,
  layers.Rescaling(1./255),
  layers.Conv2D(64, 3, activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, activation='relu'),
  layers.MaxPooling2D(),
  layers.Dropout(0.5),
  layers.Flatten(),
  layers.Dense(64, activation='relu'),
  layers.Dense(num_classes, activation='softmax')
])

#kompilacja modelu
model.compile(optimizer=RMSprop(learning_rate=0.0001),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

#trenowanie modelu
epochs=5
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs,
)

"""accuracy osiąga powyżej 0.9"""

#zapisywanie modelu
model.save('/content/drive/MyDrive/data/'+'model_ABC0_5')

model.summary()

#krzywa uczenia loss
plt.plot(history.history['loss'], label = 'loss')
plt.plot(history.history['val_loss'], label = 'val_loss')
plt.xlabel('Epoch')
plt.ylabel('Accuracy/Loss')
plt.ylim([0, 2])
plt.legend(loc='upper right')

"""model może zbytnio dopasowywać się do danych treningowych"""

#krzywa uczenia accuracy
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy/Loss')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')

"""występuje lekie przeuczenie"""

probability_model = tf.keras.Sequential([model,layers.Softmax()])

#predykcja dal test_ds
predictions = probability_model.predict(test_ds)

#ocena wydajności modelu
test_loss, test_acc = model.evaluate(test_ds)

print('\nTest accuracy:', test_acc)

"""dokładność zestawu danych testowych jest nieco mniejsza niż dokładność zestawu danych szkoleniowych"""

# pobierz predykcje dla danych testowych
y_true = np.concatenate([y for x, y in test_ds], axis=0)
y_pred = np.argmax(probability_model.predict(test_ds), axis=1)

# wyświetl raport klasyfikacji
print(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))

"""* W ogólności, model osiągnął dość niskie wyniki klasyfikacji dla danych testowych

"""

#class_names = train_ds.class_names  # lista nazw klas

# pobierz losowy obraz z testowego datasetu
image_batch, label_batch = test_ds.as_numpy_iterator().next()
images = image_batch.astype("uint8")
labels = label_batch.tolist()

# wykonaj predykcję
probability_model = tf.keras.Sequential([model, layers.Softmax()])
predictions = probability_model.predict(test_ds)

# wyświetl predykcję dla 10 losowych obrazów
num_images = 10
plt.figure(figsize=(15, 15))
for i in range(num_images):
    # pobierz prawdziwą etykietę obrazu
    true_label = class_names[labels[i]]
    
    # pobierz etykietę przewidzianą przez model
    pred_label = class_names[np.argmax(predictions[i])]
    pred_prob = np.max(predictions[i])
    
    # wyświetl obraz wraz z etykietami
    plt.subplot(5, 2, i+1)
    plt.imshow(images[i])
    plt.title(f"True label: {true_label}\nPred label: {pred_label} ({pred_prob:.2f})")
    plt.axis('off')
    
plt.show()